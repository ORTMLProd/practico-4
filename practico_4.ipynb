{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b130f2-c013-47d0-8626-083f0f64cb61",
   "metadata": {},
   "source": [
    "# Pr√°ctico 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecef2a-e013-4d24-b967-acf1b4165d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183974fa-de7a-467a-b3fb-ad5421071f52",
   "metadata": {},
   "source": [
    "**\"Transform pattern\"** en el contexto de Machine Learning se refiere a la t√©cnica de manipular y cambiar los datos de entrada antes de que sean utilizados por un modelo. \n",
    "\n",
    "Estos cambios pueden ayudar a mejorar el rendimiento del modelo y a hacer que el modelo sea m√°s robusto ante variaciones en los datos de entrada.\n",
    "\n",
    "Las transformaciones se aplican t√≠picamente durante la etapa de pre_procesamiento de los datos y pueden implicar muchas t√©cnicas diferentes, dependiendo del tipo de datos y del problema que se est√° tratando de resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b78b4d-8ec6-479d-930b-a9c9f985e641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af7356-b9cd-4173-9960-cbb284d4e75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar y normalizar el conjunto de datos \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convertir las etiquetas en one-hot\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "data_preprocessing = Sequential([\n",
    "    preprocessing.Resizing(32, 32),  # Redimensionar a 32x32\n",
    "    preprocessing.Rescaling(1./255)  # Normalizaci√≥n adicional despu√©s del redimensionamiento\n",
    "])\n",
    "\n",
    "# Define tu modelo\n",
    "model = tf.keras.models.Sequential([\n",
    "    data_preprocessing,\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 1)),  # Cambio de 3 a 1 canal de entrada\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compila y entrena el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Guarda el modelo\n",
    "model.save('transform_pattern_conv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6482f-172d-45d3-b7bf-00043ed6629a",
   "metadata": {},
   "source": [
    "En este caso, las transformaciones de datos **(Resizing y Rescaling)** se definen como capas Keras y se agregan al inicio de tu modelo. \n",
    "\n",
    "Esto significa que estas transformaciones se aplicar√°n autom√°ticamente a las im√°genes a medida que pasen por el modelo, ya sea durante el entrenamiento o durante la inferencia. \n",
    "\n",
    "Adem√°s, como las capas de preprocesamiento son parte del modelo, se guardar√°n junto con el modelo cuando lo guardes con model.save(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d97697-1330-4217-8d4b-f3e1fef30dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21c689d-9fcf-4a17-a35e-bc74c9b7e6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment tracking\n",
    "### wandb: https://wandb.ai/site\n",
    "\n",
    "\n",
    "Primero, vamos a agregar experiment tracking utilizando wandb (Weights & Biases). Esto nos va a permitir monitorear los experimentos en tiempo real, guardar nuestros modelos , resultados, y podremos compartir experimentos con otros.\n",
    "\n",
    "[Wandb collab full explained notebook ](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb#scrollTo=jufPgkgqz2eF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86d672-e91f-4554-bcc3-9b8f02cd8ac7",
   "metadata": {},
   "source": [
    "### üëü Run an experiment \n",
    "\n",
    "1.  **Start a new run** and pass in hyperparameters to track\n",
    "\n",
    "2.  **Log metrics** from training or evaluation\n",
    "\n",
    "3.  **Visualize results** in the dashboard\n",
    "\n",
    "4. **Generate alerts** in the dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084e87b-bb3a-47f0-9332-b75771f2afb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294838a-6897-4ef3-b5c9-c9656a4b20f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb237a6a-14e4-46c0-9cd8-cd2a3c0f27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "# Launch 2 experiments, trying different dropout rates\n",
    "for run in range(2):\n",
    "    \n",
    "    # Start a run, tracking hyperparameters\n",
    "    wandb.init(\n",
    "        project=\"ml-en-produccion\",\n",
    "        config={\n",
    "        \n",
    "            \"activation_1\": \"relu\",\n",
    "            \"dropout\": random.uniform(0.01, 0.80),\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"categorical_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 3,\n",
    "            \"batch_size\": 512,\n",
    "        },\n",
    "    )\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Cargar y normalizar el conjunto de datos \n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Convertir las etiquetas en one-hot\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    # Define el preprocesamiento de la imagen\n",
    "\n",
    "    data_preprocessing = Sequential([\n",
    "        preprocessing.Resizing(32, 32),  # Redimensionar a 32x32\n",
    "        preprocessing.Rescaling(1./255)  # Normalizaci√≥n adicional despu√©s del redimensionamiento\n",
    "    ])\n",
    "\n",
    "    # Define tu modelo\n",
    "    model = tf.keras.models.Sequential([\n",
    "        data_preprocessing,  \n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compila y entrena el modelo\n",
    "    model.compile(optimizer=config.optimizer, loss=config.loss,  metrics=[config.metric])\n",
    "\n",
    "    # Add WandbMetricsLogger to log metrics and WandbModelCheckpoint to log model checkpoints\n",
    "\n",
    "    wandb_callbacks = [\n",
    "        WandbMetricsLogger(),\n",
    "        WandbModelCheckpoint(filepath=\"my_model_{epoch:02d}\"),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=config.batch_size, epochs=config.epoch, validation_data=(x_test, y_test), callbacks=wandb_callbacks)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    #save model \n",
    "    model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b83a6-2a7f-4566-b728-4d811d7cf5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef8c1b0-5879-47a3-8318-8c57e403f4da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "##  W&B Alerts\n",
    "\n",
    "**[W&B Alerts](https://docs.wandb.ai/guides/track/alert)** allows you to send alerts, triggered from your Python code, to your Slack or email. There are 2 steps to follow the first time you'd like to send a Slack or email alert, triggered from your code:\n",
    "\n",
    "1) Turn on Alerts in your W&B [User Settings](https://wandb.ai/settings)\n",
    "\n",
    "2) Add `wandb.alert()` to your code:\n",
    "\n",
    "```python\n",
    "wandb.alert(\n",
    "    title=\"Low accuracy\", \n",
    "    text=f\"Accuracy is below the acceptable threshold\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c78284-a9aa-4479-aad3-3750d5b986f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# Start a wandb run\n",
    "wandb.init(project=\"alerts-intro\")\n",
    "\n",
    "# Simulating a model training loop\n",
    "acc_threshold = 0.3\n",
    "for training_step in range(1000):\n",
    "\n",
    "    # Generate a random number for accuracy\n",
    "    accuracy = round(random.random() + random.random(), 3)\n",
    "    print(f\"Accuracy is: {accuracy}, {acc_threshold}\")\n",
    "\n",
    "    # üêù Log accuracy to wandb\n",
    "    wandb.log({\"Accuracy\": accuracy})\n",
    "\n",
    "    # üîî If the accuracy is below the threshold, fire a W&B Alert and stop the run\n",
    "    if accuracy <= acc_threshold:\n",
    "        # üêù Send the wandb Alert\n",
    "        wandb.alert(\n",
    "            title=\"Low Accuracy\",\n",
    "            text=f\"Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}\",\n",
    "        )\n",
    "        print(\"Alert triggered\")\n",
    "        break\n",
    "\n",
    "# Mark the run as finished (useful in Jupyter notebooks)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9a234-68fe-402f-9cee-20a71337a05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc45011a-2fd8-4b5e-bb60-a8f772bbe99d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## H Tuning - wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfb660-ab0e-4af3-b391-54c937b1d277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',  # el m√©todo de b√∫squeda de hiperpar√°metros\n",
    "    'metric': {\n",
    "      'name': 'accuracy',\n",
    "      'goal': 'maximize'  \n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.1, 0.01, 0.001, 0.0001]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Htuning\")\n",
    "\n",
    "def train():\n",
    "    run = wandb.init()\n",
    "    config = run.config\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size=config.batch_size, epochs=5, validation_data=(x_test, y_test), callbacks=[WandbCallback()])\n",
    "\n",
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba221d39-c4b9-4f06-a2b0-d32a54277d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
